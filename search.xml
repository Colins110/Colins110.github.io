<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[raft原理]]></title>
    <url>%2F2020%2F06%2F27%2Fraft%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[关于Raft原理，许多朋友也许不是很明白原理，下面的地址是一个好玩的Raft动画，看完后能够很快的掌握Raft原理：http://thesecretlivesofdata.com/raft/ 动画中的一些概念和简要原理总结如下： raft原理在Raft中，每个结点会处于下面三种状态中的一种： follower：所有结点都以follower的状态开始。如果没收到leader消息则会变成candidate状态。 candidate：会向其他结点“拉选票”，如果得到大部分的票则成为leader。这个过程就叫做Leader选举(Leader Election)。 leader：所有对系统的修改都会先经过leader。每个修改都会写一条日志(log entry)。leader收到修改请求后的过程如下，这个过程叫做日志复制(Log Replication)： 复制日志到所有follower结点(replicate entry) 大部分结点响应时才提交日志 通知所有follower结点日志已提交 所有follower也提交日志 现在整个系统处于一致的状态 三种角色的状态转换关系如下: Leader Election当follower在选举超时时间(election timeout)内未收到leader的心跳消息(append entries)，则变成candidate状态。为了避免选举冲突，这个超时时间是一个150~300ms之间的随机数。 成为candidate的结点发起新的选举期(election term)去“拉选票”： 重置自己的计时器 投自己一票 发送 Request Vote消息如果接收结点在新term内没有投过票那它就会投给此candidate，并重置它自己的选举超时时间。candidate拉到大部分选票就会成为leader，并定时发送心跳——Append Entries消息，去重置各个follower的计时器。当前Term会继续直到某个follower接收不到心跳并成为candidate。 如果不巧两个结点同时成为candidate都去“拉票”怎么办？这时会发生Splite Vote情况。两个结点可能都拉到了同样多的选票，难分胜负，选举失败，本term没有leader。之后又有计时器超时的follower会变成candidate，将term加一并开始新一轮的投票。 Log Replication当发生改变时，leader会复制日志给follower结点，这也是通过Append Entries心跳消息完成的。前面已经列举了Log Replication的过程，这里就不重复了。 Raft能够正确地处理网络分区（“脑裂”）问题。假设A~E五个结点，B是leader。如果发生“脑裂”，A、B成为一个子分区，C、D、E成为一个子分区。此时C、D、E会发生选举，选出C作为新term的leader。这样我们在两个子分区内就有了不同term的两个leader。这时如果有客户端写A时，因为B无法复制日志到大部分follower所以日志处于uncommitted未提交状态。而同时另一个客户端对C的写操作却能够正确完成，因为C是新的leader，它只知道D和E。 当网络通信恢复，B能够发送心跳给C、D、E了，却发现“改朝换代”了，因为C的term值更大，所以B自动降格为follower。然后A和B都回滚未提交的日志，并从新leader那里复制最新的日志。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>raft</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[devicemapper源码理解]]></title>
    <url>%2F2020%2F04%2F01%2Fdevicemapper%E6%BA%90%E7%A0%81%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[device-mapper.htable的类型，mapped_device 的内存池和请求队列enum dm_queue_mode { DM_TYPE_NONE = 0, DM_TYPE_BIO_BASED = 1, DM_TYPE_REQUEST_BASED = 2, DM_TYPE_MQ_REQUEST_BASED = 3, DM_TYPE_DAX_BIO_BASED = 4,}; 一些函数原型如：typedef int (dm_ctr_fn) (struct dm_target target, unsigned int argc, char **argv); /* The map function must return: &lt; 0: error = 0: The target will handle the io by resubmitting it later = 1: simple remap complete = 2: The target wants to push back the io/typedef int (dm_map_fn) (struct dm_target ti, struct bio bio); /* Returns: &lt; 0 : error (currently ignored) 0 : ended successfully 1 : for some reason the io has still not completed (eg, multipath target might want to requeue a failed io). 2 : The target wants to push back the io/typedef int (dm_endio_fn) (struct dm_target *ti,struct bio *bio, int error); target_typestruct target_type { uint64_t features; const char name; struct module module; unsigned version[3]; dm_ctr_fn ctr; dm_dtr_fn dtr; dm_map_fn map; dm_map_request_fn map_rq; dm_clone_and_map_request_fn clone_and_map_rq; dm_release_clone_request_fn release_clone_rq; dm_endio_fn end_io; dm_request_endio_fn rq_end_io; dm_presuspend_fn presuspend; dm_presuspend_undo_fn presuspend_undo; dm_postsuspend_fn postsuspend; dm_preresume_fn preresume; dm_resume_fn resume; dm_status_fn status; dm_message_fn message; dm_prepare_ioctl_fn prepare_ioctl; dm_merge_fn merge; dm_busy_fn busy; dm_iterate_devices_fn iterate_devices; dm_io_hints_fn io_hints; dm_dax_direct_access_fn direct_access; dm_dax_memcpy_fromiovecend_fn dax_memcpy_fromiovecend; dm_dax_memcpy_toiovecend_fn dax_memcpy_toiovecend; /* For internal device-mapper use. */ struct list_head list; }; 2020-4-5从devicemapper 初始化开始看：在dm-ioctl.c中创建混杂设备(混杂设备是一种字符设备)：1234567891011121314151617181920int __init dm_interface_init(void)&#123; int r; r = dm_hash_init(); if (r) return r; r = misc_register(&amp;_dm_misc); //注册混杂设备 if (r) &#123; DMERR("misc_register failed for control device"); dm_hash_exit(); return r; &#125; DMINFO("%d.%d.%d%s initialised: %s", DM_VERSION_MAJOR, DM_VERSION_MINOR, DM_VERSION_PATCHLEVEL, DM_VERSION_EXTRA, DM_DRIVER_EMAIL); return 0;&#125; 在dm.c 调用并初始化123456static struct miscdevice _dm_misc = &#123; .minor = MAPPER_CTRL_MINOR, .name = DM_NAME, .nodename = DM_DIR "/" DM_CONTROL_NODE, .fops = &amp;_ctl_fops //设置混杂设备的一些操作&#125;; 混杂设备具体的操作：123456789static const struct file_operations _ctl_fops = &#123; .open = dm_open, .release = dm_release, .poll = dm_poll, .unlocked_ioctl = dm_ctl_ioctl, .compat_ioctl = dm_compat_ctl_ioctl, .owner = THIS_MODULE, .llseek = noop_llseek,&#125;; 在dm_ctl_ioctl中实现具体的ioctl操作dm_ctl_ioctl() -&gt; ctl_ioctl() -&gt; lookup_ioctl() //查找对应的ioctl操作在 ctl_ioctl中执行对应的ioctl操作 123456789101112131415161718192021222324252627282930313233343536static ioctl_fn lookup_ioctl(unsigned int cmd, int *ioctl_flags)&#123; static const struct &#123; int cmd; int flags; ioctl_fn fn; &#125; _ioctls[] = &#123; &#123;DM_VERSION_CMD, 0, NULL&#125;, /* version is dealt with elsewhere */ &#123;DM_REMOVE_ALL_CMD, IOCTL_FLAGS_NO_PARAMS | IOCTL_FLAGS_ISSUE_GLOBAL_EVENT, remove_all&#125;, &#123;DM_LIST_DEVICES_CMD, 0, list_devices&#125;, &#123;DM_DEV_CREATE_CMD, IOCTL_FLAGS_NO_PARAMS | IOCTL_FLAGS_ISSUE_GLOBAL_EVENT, dev_create&#125;, &#123;DM_DEV_REMOVE_CMD, IOCTL_FLAGS_NO_PARAMS | IOCTL_FLAGS_ISSUE_GLOBAL_EVENT, dev_remove&#125;, &#123;DM_DEV_RENAME_CMD, IOCTL_FLAGS_ISSUE_GLOBAL_EVENT, dev_rename&#125;, &#123;DM_DEV_SUSPEND_CMD, IOCTL_FLAGS_NO_PARAMS, dev_suspend&#125;, &#123;DM_DEV_STATUS_CMD, IOCTL_FLAGS_NO_PARAMS, dev_status&#125;, &#123;DM_DEV_WAIT_CMD, 0, dev_wait&#125;, &#123;DM_TABLE_LOAD_CMD, 0, table_load&#125;, &#123;DM_TABLE_CLEAR_CMD, IOCTL_FLAGS_NO_PARAMS, table_clear&#125;, &#123;DM_TABLE_DEPS_CMD, 0, table_deps&#125;, &#123;DM_TABLE_STATUS_CMD, 0, table_status&#125;, &#123;DM_LIST_VERSIONS_CMD, 0, list_versions&#125;, &#123;DM_TARGET_MSG_CMD, 0, target_message&#125;, &#123;DM_DEV_SET_GEOMETRY_CMD, 0, dev_set_geometry&#125;, &#123;DM_DEV_ARM_POLL, IOCTL_FLAGS_NO_PARAMS, dev_arm_poll&#125;, &#125;; if (unlikely(cmd &gt;= ARRAY_SIZE(_ioctls))) return NULL; *ioctl_flags = _ioctls[cmd].flags; return _ioctls[cmd].fn;&#125; 看一下创建一个mapping device的过程：12345678910111213141516171819202122232425262728293031static int dev_create(struct file *filp, struct dm_ioctl *param, size_t param_size)&#123; int r, m = DM_ANY_MINOR; struct mapped_device *md; r = check_name(param-&gt;name); if (r) return r; if (param-&gt;flags &amp; DM_PERSISTENT_DEV_FLAG) m = MINOR(huge_decode_dev(param-&gt;dev)); r = dm_create(m, &amp;md); if (r) return r; r = dm_hash_insert(param-&gt;name, *param-&gt;uuid ? param-&gt;uuid : NULL, md); if (r) &#123; dm_put(md); dm_destroy(md); return r; &#125; param-&gt;flags &amp;= ~DM_INACTIVE_PRESENT_FLAG; __dev_status(md, param); dm_put(md); return 0;&#125;]]></content>
  </entry>
  <entry>
    <title><![CDATA[[转]理解Makefile中的KERNELRELEASE]]></title>
    <url>%2F2020%2F03%2F17%2F%E8%BD%AC-%E7%90%86%E8%A7%A3Makefile%E4%B8%AD%E7%9A%84KERNELRELEASE%2F</url>
    <content type="text"><![CDATA[Linux内核是一种单体内核，但是通过动态加载模块的方式，使它的开发非常灵活方便。那么，它是如何编译内核的呢？我们可以通过分析它的Makefile入手。以下是一个简单的hello内核模块的Makefile. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667#########################Makefile1#########################ifneq ($(KERNELRELEASE),)obj-m:=hello.oelseKERNELDIR:=/lib/modules/$(shell uname -r)/buildPWD:=$(shell pwd)default: $(MAKE) -C $(KERNELDIR) M=$(PWD) modulesclean: rm -rf *.o *.mod.c *.mod.o *.koendif################################################################################Makefile2#########################ifneq ($(KERNELRELEASE),)obj-m :=hello.oelseKDIR:= /lib/modules/2.6.29.4-167.fc11.i686.PAE/buildall: make -C $(KDIR) M=$(PWD) modulesclean:rm -f *.ko *.o *.mod.o *.mod.c .symversendif################################################################################Makefile3#########################ifneq ($(KERNELRELEASE),)obj-m := hello.oelsePWD := $(shell pwd)KVER := $(shell uname -r)KDIR := /lib/modules/$(KVER)/buildall: $(MAKE) -C $(KDIR) M=$(PWD) modulesclean: rm -rf .*.cmd *.o *.mod.c *.ko .tmp_versionsendif####################################################### 当我们写完一个hello模块，只要使用以上的makefile。然后make一下就行。假设我们把hello模块的源代码放在/home/study/prog/mod/hello/下。当我们在这个目录运行make时，make是怎么执行的呢？ LDD3第二章第四节“编译和装载”中只是简略地说到该Makefile被执行了两次，但是具体过程是如何的呢？ 首先，由于make 后面没有目标，所以make会在Makefile中的第一个不是以.开头的目标作为默认的目标执行。于是default成为make的目标。make会执行 $(MAKE) -C $(KERNELDIR) M=$(PWD) modules shell是make内部的函数,假设当前内核版本是2.6.13-study,所以$(shell uname -r)的结果是 2.6.13-study 这里，实际运行的是 make -C /lib/modules/2.6.13-study/build M=/home/study/prog/mod/hello/ modules，/lib/modules/2.6.13-study/build是一个指向内核源代码/usr/src/linux的符号链接。可见，make执行了两次。第一次执行时是读hello模块的源代码所在目录/home/s tudy/prog/mod/hello/下的Makefile。 第二次执行时是执行/usr/src/linux/下的Makefile时. 但是还是有不少令人困惑的问题： 1.这个KERNELRELEASE也很令人困惑，它是什么呢？在/home/study/prog/mod/hello/Makefile中是没有定义这个变量的，所以起作用的是else…endif这一段。不过，如果把hello模块移动到内核源代码中。例如放到/usr/src/linux/driver/中， KERNELRELEASE就有定义了。 在/usr/src/linux/Makefile中有 162 KERNELRELEASE=$(VERSION).$(PATCHLEVEL).$(SUBLEVEL)$(EXTRAVERSION)$(LOCALVERSION) 这时候，hello模块也不再是单独用make编译，而是在内核中用make modules进行 编译。 用这种方式，该Makefile在单独编译和作为内核一部分编译时都能正常工作。 2.这个obj-m := hello.o什么时候会执行到呢？ 在执行： make -C /lib/modules/2.6.13-study/build M=/home/study/prog/mod/hello/ modules时，make 去/usr/src/linux/Makefile中寻找目标modules: 862 .PHONY: modules 863 modules: $(vmlinux-dirs) $(if $(KBUILD_BUILTIN),vmlinux) 864 @echo ‘ Building modules, stage 2.’; 865 $(Q)$(MAKE) -rR -f $(srctree)/scripts/Makefile.modpost 可以看出，分两个stage: 1.编译出hello.o文件。 2.生成hello.mod.o hello.ko 在这过程中，会调用 make -f scripts/Makefile.build obj=/home/study/prog/mod/hello 而在 scripts/Makefile.build会包含很多文件： 011 -include .config 012 013 include $(if $(wildcard $(obj)/Kbuild), $(obj)/Kbuild, $(obj)/Makefile) 其中就有/home/study/prog/mod/hello/Makefile 这时 KERNELRELEASE已经存在。所以执行的是： obj-m:=hello.o 关于make modules的更详细的过程可以在scripts/Makefile.modpost文件的注释中找到。如果想查看make的整个执行过程，可以运行make -n。 123456789101112131415161718192021222324252627282930313233343536373839#include &lt;linux/init.h&gt;#include &lt;linux/module.h&gt; MODULE_LICENSE("GPL");MODULE_AUTHOR("feixiaoxing");MODULE_DESCRIPTION("This is just a hello module!\n"); static int __init hello_init(void)&#123; printk(KERN_EMERG "hello, init\n"); return 0;&#125; static void __exit hello_exit(void)&#123; printk(KERN_EMERG "hello, exit\n");&#125; module_init(hello_init);module_exit(hello_exit); 加载模块就是输入insmod hello.ko，卸载模块就是rmmod hello。在这过程中，我们都可以看到相应的打印内容。当然，朋友们可以一直往里面加代码，一步步调试，一步步学习，只要坚持和总结，都是可以学习好linux的驱动代码的。 转自《理解Makefile中的KERNELRELEASE》]]></content>
      <categories>
        <category>kernel</category>
      </categories>
      <tags>
        <tag>makefile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu下编译内核模块]]></title>
    <url>%2F2020%2F03%2F17%2Fubuntu%E4%B8%8B%E7%BC%96%E8%AF%91%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[在ubuntu下编写内核模块，需要一个源文件和一个makefile文件。模块源文件hello.c:123456789101112131415#include&lt;linux/init.h&gt;#include&lt;linux/module.h&gt;MODULE_LICENSE("Dual BSD/GPL");static int hello_init(void)&#123; printk(KERN_ALERT "Hello,world\n"); return 0;&#125;static void hello_exit(void)&#123; printk(KERN_ALERT "GoodBye,colin!\n");&#125;module_init(hello_init);module_exit(hello_exit); makefile文件:123456789101112131415161718192021222324252627282930313233343536373839404142434445# Comment/uncomment the following line to disable/enable debugging#DEBUG = y# Add your debugging flag (or not) to CFLAGSifeq ($(DEBUG),y) DEBFLAGS = -O -g -DSCULL_DEBUG # "-O" is needed to expand inlineselse DEBFLAGS = -O2endifLDDINC=$(PWD)/../includeEXTRA_CFLAGS += $(DEBFLAGS)EXTRA_CFLAGS += -I$(LDDINC)ifneq ($(KERNELRELEASE),)# call from kernel build system#scull-objs := main.o pipe.o access.oobj-m := hello.oelseKERNELDIR ?= /lib/modules/$(shell uname -r)/buildPWD := $(shell pwd)modules: $(MAKE) -C $(KERNELDIR) M=$(PWD) modulesendifclean: rm -rf *.o *~ core .depend .*.cmd *.ko *.mod.c .tmp_versionsdepend .depend dep: $(CC) $(EXTRA_CFLAGS) -M *.c &gt; .dependifeq (.depend,$(wildcard .depend))include .dependendif]]></content>
      <tags>
        <tag>kernel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos获取内核源码]]></title>
    <url>%2F2020%2F03%2F08%2Fcentos%E8%8E%B7%E5%8F%96%E5%86%85%E6%A0%B8%E6%BA%90%E7%A0%81%2F</url>
    <content type="text"><![CDATA[参考centos wiki 常见编译目录 12[user@host]$ mkdir -p ~/rpmbuild/&#123;BUILD,BUILDROOT,RPMS,SOURCES,SPECS,SRPMS&#125;[user@host]$ echo '%_topdir %(echo $HOME)/rpmbuild' &gt; ~/.rpmmacros 安装必要的工具 12345[root@host]# yum install asciidoc audit-libs-devel bash bc binutils binutils-devel bison diffutils elfutils[root@host]# yum install elfutils-devel elfutils-libelf-devel findutils flex gawk gcc gettext gzip hmaccalc hostname java-devel[root@host]# yum install m4 make module-init-tools ncurses-devel net-tools newt-devel numactl-devel openssl[root@host]# yum install patch pciutils-devel perl perl-ExtUtils-Embed pesign python-devel python-docutils redhat-rpm-config[root@host]# yum install rpm-build sh-utils tar xmlto xz zlib-devel 安装包含源码的rpm包 1[user@host]$ rpm -i http://vault.centos.org/7.7.1908/updates/Source/SPackages/kernel-3.10.0-1062.12.1.el7.src.rpm 2&gt;&amp;1 | grep -v exist 可以使用cat /etc/redhat-release和uname -r确定要安装的内核源码。在线安装比较慢，可以到http://vault.centos.org下载后安装。]]></content>
      <categories>
        <category>kernel</category>
      </categories>
      <tags>
        <tag>内核</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos安装chacha20]]></title>
    <url>%2F2020%2F02%2F08%2Fcentos%E5%AE%89%E8%A3%85chacha20%2F</url>
    <content type="text"><![CDATA[1234567891011yum install m2crypto gcc -ywget https://download.libsodium.org/libsodium/releases/libsodium-1.0.18.tar.gztar zxf libsodium-1.0.18.tar.gzcd libsodium-1.0.18./configuremake &amp;&amp; make installecho "include ld.so.conf.d/*.conf" &gt; /etc/ld.so.confecho "/lib" &gt;&gt; /etc/ld.so.confecho "/usr/lib64" &gt;&gt; /etc/ld.so.confecho "/usr/local/lib" &gt;&gt; /etc/ld.so.confldconfig]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>centos</tag>
        <tag>chacha20</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[转]详解LMA&VMA(浅显易懂)]]></title>
    <url>%2F2020%2F02%2F07%2F%E8%BD%AC-%E8%AF%A6%E8%A7%A3LMA-VMA-%E6%B5%85%E6%98%BE%E6%98%93%E6%87%82%2F</url>
    <content type="text"><![CDATA[关于LMA和VMA，这个问题，有点点小复杂，不过，此处，我会把我的理解，尽量通过通俗的方式解释出来，以方便理解。当然，鄙人水平有限，难免有错，希望各位批评指正。 一般提及LMA和VMA，多数情况都是和ld，链接器相关的。在了解这两个名词的详细含义之前，有些基本知识和前提要说一下：［基础知识］1。从你写的源代码到执行你的程序，一般经历了这几个过程：源代码编辑 -&gt; 编译 -&gt; 链接 -&gt; 装载 -&gt; 执行2。编译，简单说就是用编译工具，将你的源码，变成可以执行的二进制代码，也叫做目标文件，当然只是对应某一种硬件平台，比如此处我用的是Intel的X86系列的CPU，编译出来的，就是针对X86的二进制代码。3。链接就是，将多个目标文件合并为一个目标文件，称作可执行文件。4。每个目标文件都包含一连串的section，最常见，最基础的至少有：.text，代码段，就是CPU要运行的指令代码；.data，数据段，程序中包含的一些数据，放在这个段里；.bss，未初始化段，记录了程序里有哪些未初始化的变量，就相当于只记录对应的名字，留着程序运行前去初始化为0，所以，此处并不占用具体空间。打个比方就是，只记录人名，没有人站在这里占地方，而对应的.text和.data段，都是既有人名（函数或者变量名）,又占对应的地方（包含具体空间记录到底是什么指令代码和数据的数值是多少）。5。section一般可以分为loadable与allocatable.通俗点说就是：loadable，可加载，就是，原先目标文件里面包含对应的代码或数据，所以，装载器要把这些内容，load到对应的地址，以便程序可以运行；而allocatable，可分配的，最简单理解就是上面提到的.bss段，那里记录了人名，到时候，你要给这些人名分配空间给你站的地方，对应着也就是变量所要占用的具体内存空间了。其他还有既不是loadbale的，也不是allocatable的，比如只存储debug信息的段，此处不多解释。［前提］程序已经编译好了，有了一个可执行文件，也叫目标文件，二进制文件，才会有后面的把程序装载，运行的事情。 看完了基础知识和前提，再说我们此处的主题，才能更加清楚是咋回事：对于目标文件中的loadable或allocatable的section，其都有两个地址：VMA 和 LMA 。知道了其来由，再看具体解释：［LMA 详解］LMA的英文原版解释：LMA（Load Memory Address）： the address at which the section will be loaded.什么是Load Memory Address，内存装载地址呢? 此处，单单从名字上，我们就可以看出几层意思：1。load，装载为何要装载呢？ 因为，如果想要使你的程序（即经历过，由你的源码，通过编译器的编译，链接器的链接，形成的那个可执行文件），能在内存里面运行，那么肯定涉及到一点，就是，有人，把你的这个程序，，从此处常见的存储器硬盘里面，搬到内存里面去了，然后才有可能运行。而这里的装载，就是对应这个意思。就是把程序，从硬盘里面，装载Load，到内存里面去了。对应地，放到内存哪里去了呢？就是LMA，Load Memory Address，就是把你的程序中的对应的内容，详细点说就是，把其中的.text代码段，.data数据段等内容，搬到，也就是copy拷贝到，内存的LMA地址处了。2。Memory，内存上面已经解释了，这里再多说几句。程序运行的本质，就是CPU读取到指令，然后执行。这里就涉及到，如果想要你的程序运行，首先，你应该把对应的指令，放到合适的地方，CPU 才能读到，才能执行。此处合适的地方，有人想到，直接放到硬盘这里，CPU过来读取，然后执行不就可以了吗，还不用这么麻烦地将（指令）代码搬来搬去的，多省事。但是实际上，系统就是这么“笨”地搬来搬去，原因在于，从硬盘上直接读取指令，速度比直接从内存，一般PC 上是各种类型的RAM，比如DDR，此处统称为Memory/内存，要慢很多倍，所以，系统才会不嫌弃麻烦，把代码拷贝到内存里面去，然后从内存里面读取指令，然后执行，这样效率会高很多。所以，此处简单说就是，为了总体效率，对于普通系统，比如PC，程序的执行都是在Memory，内存里面执行的。 因此，用一句话总结就是：代码被装载到内存的某个地方，那个地方的地址，就是LMA 。 ［VMA 详解］英文解释：VMA（Virtual Memory Address）：the address the section will have when the output file is run;那啥是虚拟内存地址呢？简单说就是，你程序运行时候的所对应的地址。此处所谓的虚拟，一般来说，指的是启用了MMU之后，才有了虚拟地址和实地址。此处，我们可以简单的理解为，就是内存的实际地址即可。程序运行前，要把程序的内容，拷贝到对应的内存地址处，然后才能运行的。因此，一句话总结就是：代码要运行的时候，此时对应的地址，就是VMA。 ［理解此句：在多数情况下，LMA和VMA是相等的］这句话，说白了，可以（武断地）这么理解：如果是普通PC电脑，也就是上面说的，大多数情况下，那么LMA和VMA是一样的，也就是，程序被加载到内存的什么地方，也就在什么地方运行。如果是嵌入式系统，也就是相对的“少数情况”，LMA和VMA不一样。而其中最常见的一种情况就是，程序被放到ROM中，比如设置为只读的Nor Flash中，也就是LMA的地址是Nor Flash的地址，此如随便举例为0x10000000，而程序要运行时候的地址是内存地址，比如0x30000000,也就是VMA 是0x30000000，这时候，就要我们自己保证，在程序运行之前，把自己的程序，从LMA＝0x10000000拷贝到VMA＝0x3000000处，然后程序才可以正常运行。 有人会问，反正对于ROM来说，CPU 也是可以直接从ROM里面读取代码，然后运行的。为何还要前面提到的，弄个LMA 和VMA不同，搬来搬去的呢？因为ROM，顾名思义，是只读的，只能读取，不能写入的。而程序中的代码段，由于只是被读取，不涉及到修改写入，是没有问题的。但是对于数据段和bss位初始化段来说，里面的所有的程序的变量，多数都是在运行的时候，不仅要读取，而且要被修改成新的值，然后写入新的值的，所以，如果还是放到ROM里面，就没法修改写入了。而且，另一个原因是，CPU从ROM，比如常见的Nor Flash中读取代码的速度，要远远小于从RAM，比如常见的SDRAM，中读取的速度，所以，才会牵扯到将代码烧写到ROM里面，然后代码的最开始，将此部分程序reaload，重载，也就是从此处的ROM的地址，即LMA，重新拷贝到SDRAM中去，也就是VMA的地方，然后从那里运行。 ［后记］关于LMA 和 VMA：Linker，链接器的作用：1。将LMA写到（可执行的）二进制文件里面去2。解析符号。即，把不同的符号，根据符号表中的信息，转换成对应的地址。此处只涉及VMA，即程序运行时候的地址。 Loader，装载器的作用：1。从二进制文件中读出对应的段的信息，比如text，data，bss等段的信息，将内容拷贝到对应的LMA的地址处。此谓，装载（对应内容）到装载地址（LMA）。2。如果发现VMA!=LMA, 即 程序运行时候的地址，和刚刚把程序内容拷贝到的地址LMA，两者不一样，那么就要把对应的内容，此处主要是data，数据段的内容，从刚刚装载到的位置，LMA处，拷贝到VMA处，这样，程序运行的时候，才能够在执行的时候，找到对应的VMA处的变量，才能找到对应的值，程序才能正常运行。]]></content>
      <categories>
        <category>6.828</category>
      </categories>
      <tags>
        <tag>elf</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[转]A20地址线问题]]></title>
    <url>%2F2020%2F02%2F06%2F%E8%BD%AC-A20%E5%9C%B0%E5%9D%80%E7%BA%BF%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[A20地址线并不是打开保护模式的关键，只是在保护模式下，不打开A20地址线，你将无法访问到所有的内存（具体参考下面的第5点） 用于80286与8086兼容 用于80286处于实模式下时，防止用户程序访问到100000h~10FFEFh之间的内存（高端内存） 8086模式，A20关闭的情况下，访问超过1MB内存时，会自动回卷 8086模式下，A20打开的情况下，访问超过1MB内存，就真实的访问 保护模式下，A20关闭（始终为0），则用户的地址只能是：0 - (1MB-1), 2 - (3MB-1), 4 - (5MB-1)，我们可以这样设想，A20为个位数（以1MB为单位），如果它始终为0，你永远不可能让这个数变成奇数。 保护模式下，A20开启，则可以访问全地址，没有奇偶MB的问题。 调用BIOS中断就可以实现A20 Gate的控制功能。这个BIOS中断为 INT 15h,AX=2401h。被称为Fast A20。 下面转载一篇文档:A20地址线问题 很多稀奇古怪的东西都是由于系统升级时，为了保持向下兼容而产生的，A20Gate就是其中之一。 在8086/8088中，只有20根地址总线，所以可以访问的地址是2^20=1M，但由于8086/8088是16位地址模式，能够表示的地址范围是0-64K，所以为了在8086/8088下能够访问1M内存，Intel采取了分段的模式：16位段基地址:16位偏移。其绝对地址计算方法为：16位基地址左移4位+16位偏移=20位地址。 但这种方式引起了新的问题，通过上述分段模式，能够表示的最大内存为：FFFFh:FFFFh=FFFF0h+FFFFh=10FFEFh=1M+64K-16Bytes（1M多余出来的部分被称做高端内存区HMA）。但8086/8088只有20位地址线，如果访问100000h~10FFEFh之间的内存，则必须有第21根地址线。所以当程序员给出超过1M（100000H-10FFEFH）的地址时，系统并不认为其访问越界而产生异常，而是自动从重新0开始计算，也就是说系统计算实际地址的时候是按照对1M求模的方式进行的，这种技术被称为wrap-around。 到了80286，系统的地址总线发展为24根，这样能够访问的内存可以达到2^24=16M。Intel在设计80286时提出的目标是，在实模式下，系统所表现的行为应该和8086/8088所表现的完全一样，也就是说，在实模式下，80286以及后续系列，应该和8086/8088完全兼容。但最终，80286芯片却存在一个BUG：如果程序员访问100000H-10FFEFH之间的内存，系统将实际访问这块内存，而不是象过去一样重新从0开始。 为了解决上述问题，IBM使用键盘控制器上剩余的一些输出线来管理第21根地址线（从0开始数是第20根），被称为A20Gate：如果A20 Gate被打开，则当程序员给出100000H-10FFEFH之间的地址的时候，系统将真正访问这块内存区域；如果A20Gate被禁止，则当程序员给出100000H-10FFEFH之间的地址的时候，系统仍然使用8086/8088的方式。绝大多数IBM PC兼容机默认的A20Gate是被禁止的。由于在当时没有更好的方法来解决这个问题，所以IBM使用了键盘控制器来操作A20 Gate，但这只是一种黑客行为，毕竟A20Gate和键盘操作没有任何关系。在许多新型PC上存在着一种通过芯片来直接控制A20 Gate的BIOS功能。从性能上，这种方法比通过键盘控制器来控制A20Gate要稍微高一点。 上面所述的内存访问模式都是实模式，在80286以及更高系列的PC中，即使A20Gate被打开，在实模式下所能够访问的内存最大也只能为10FFEFH，尽管它们的地址总线所能够访问的能力都大大超过这个限制。为了能够访问10FFEFH以上的内存，则必须进入保护模式。（其实所谓的实模式，就是8086/8088的模式，这种模式存在的唯一理由就是为了让旧的程序能够继续正常的运行在新的PC体系上） A20 Gate inProtected Mode 从80286开始，系统出现了一种新的机制，被称为保护模式。到了80386，保护模式得到了进一步的完善和发展，并且对于80386以后的芯片，保护模式的变化就非常小了。 我们在上一节已经谈到，如果要访问更多的内存，则必须进入保护模式，那么，在保护模式下，A20Gate对于内存访问有什么影响呢？ 为了搞清楚这一点，我们先来看一看A20的工作原理。A20，从它的名字就可以看出来，其实它就是对于20-bit（从0开始数）的特殊处理(也就是对第21根地址线的处理)。如果A20Gate被禁止，对于80286来说，其地址为24bit，其地址表示为EFFFFF；对于80386极其随后的32-bit芯片来说，其地址表示为FFEFFFFF。这种表示的意思是如果A20Gate被禁止，则其第20-bit在CPU做地址访问的时候是无效的，永远只能被作为0；如果A20 Gate被打开，则其第20-bit是有效的，其值既可以是0，又可以是1。 所以，在保护模式下，如果A20Gate被禁止，则可以访问的内存只能是奇数1M段，即1M,3M,5M…，也就是00000-FFFFF,200000-2FFFFF,300000-3FFFFF…。如果A20 Gate被打开，则可以访问的内存则是连续的。 How to Enable A20Gate 多数PC都使用键盘控制器（8042芯片）来处理A20Gate。 从理论上讲，打开A20Gate的方法是通过设置8042芯片输出端口（64h）的2nd-bit，但事实上，当你向8042芯片输出端口进行写操作的时候，在键盘缓冲区中，或许还有别的数据尚未处理，因此你必须首先处理这些数据。 流程如下： 1. 禁止中断； 2. 等待，直到8042 Inputbuffer为空为止； 3. 发送禁止键盘操作命令到8042Input buffer； 4. 等待，直到8042 Inputbuffer为空为止； 5. 发送读取8042 OutputPort命令； 6. 等待，直到8042 Outputbuffer有数据为止； 7. 读取8042 Outputbuffer，并保存得到的字节； 8. 等待，直到8042 Inputbuffer为空为止； 9. 发送Write 8042Output Port命令到8042 Input buffer； 10. 等待，直到8042 Inputbuffer为空为止； 11. 将从8042 OutputPort得到的字节的第2位置1（OR 2），然后写入8042 Input buffer； 12. 等待，直到8042 Inputbuffer为空为止； 13. 发送允许键盘操作命令到8042Input buffer； 14. 打开中断。 下面代码是一个相关实现：123456789101112131415161718192021222324252627282930313233enable_a20:sticallwait_input_emptymovb $0xAD, %aloutb $0x64 #disableKeyboardcallwait_input_emptymovb $0xD0, %aloutb $0x64 #command-read 8042 output portcallwait_output_fullinb $0x60 # got thevalue of 8042 output port and save itpushb %alcallwait_input_emptymovb $0xD1, %aloutb $0x64 #command-write 8042 output portcallwait_input_emptypopb %alorb $0x02, %al #enable A20 Gateoutb $0x60callwait_input_emptymovb $0xAE, %aloutb $0x64 #enableKeyboardcliretwait_input_empty:rp1: inb $0x64testb %al, 0x02jnz rp1retwait_output_full:rp2: inb $0x64testb %al, 0x01jz rp2ret 以上描述的是一种和IBMPC完全兼容的，通过键盘控制器控制A20 Gate的方法。但是，正象我们在前面所提到的，A20 Gate与键盘操作完全没有关系，IBM之所以将A20Gate的功能控制放在键盘控制器上，完全是一种为了弥补Intel 80286与Intel8086/8088不完全兼容的缺陷，而采取的Hacker行为，所以在许多新型PC上存在着一种通过芯片来直接控制A20 Gate的BIOS功能，我们在RealMode下只需要调用BIOS中断就可以实现A20 Gate的控制功能。这个BIOS中断为 INT 15h, AX=2401h。被称为Fast A20。movw $0x2401, %axint $0x15 How to Detect ifA20 Gate has been Enabled?我们在之前已经提到，如果A20Gate被打开了，则在实模式下，程序员可以直接访问100000H~10FFEFH之间的内存，如果A20Gate被禁止，则在实模式下，若程序员访问100000H~10FFEFH之间的内存，则会被硬件自动转换为0H~0FFEFH之间的内存，所以我们可以利用这个差异来检测A20Gate是否被打开。1234567891011121314151617181920212223242526272829# This routine testswhether or not A20 is enabled. If so, it# exits with zf = 0.# The memory addressused, 0x200, is the int $0x80 vector, which# should be safe.A20_TEST_ADDR =4*0x80A20_TEST_LOOPS = 3a20_test:pushw %cxpushw %axxorw %cx, %cxmovw %cx, %fs # Lowmemorydecw %cxmovw %cx, %gs # Highmemory areamovw$A20_TEST_LOOPS, %cxmovw%fs:(A20_TEST_ADDR), %axpushw %axa20_test_wait:incw %axmovw %ax,%fs:(A20_TEST_ADDR)call delay #Serialize and make delay constantcmpw%gs:(A20_TEST_ADDR+0x10), %axloope a20_test_waitpopw%fs:(A20_TEST_ADDR)popw %axpopw %cxret delay:outb %al,$0x80ret]]></content>
      <categories>
        <category>6.828</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux密钥登陆]]></title>
    <url>%2F2020%2F02%2F06%2Flinux%E5%AF%86%E9%92%A5%E7%99%BB%E9%99%86%2F</url>
    <content type="text"><![CDATA[生成密钥: ssh-keygen -t rsa -C &quot;your_email@example.com&quot;发送公钥: ssh-copy-id &lt;username&gt;@&lt;host&gt;]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>ssh密钥登陆</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OSTEP虚拟化]]></title>
    <url>%2F2020%2F01%2F30%2FOSTEP%E8%99%9A%E6%8B%9F%E5%8C%96%2F</url>
    <content type="text"><![CDATA[进程的概念 进程:运行的程序(runing program) 通常情况下，一台pc上需要同时运行多个进程，以便提供易用性。 需要解决的问题：如何提供多个CPU的假象-&gt;虚拟化CPU技术(分时复用CPU time sharing of CPU) 底层机制(mechanisms eg.上下文切换)+上层策略(policies eg.进程调度策略) 实现分时复用 进程的组成: 地址空间(包含指令和数据等)、寄存器(eg. IP、SP等)、持久存储设备 进程API: Create: An operating system must include some method to create new processes. When you type a command into the shell, or double-click on an application icon, the OS is invoked to create a new process to run the program you have indicated. Destroy: As there is an interface for process creation, systems also provide an interface to destroy processes forcefully. Of course, many processes will run and just exit by themselves when complete; when they don’t, however, the user may wish to kill them, and thus an interface to halt a runaway process is quite useful. Wait: Sometimes it is useful to wait for a process to stop running; thus some kind of waiting interface is often provided. Miscellaneous Control: Other than killing or waiting for a process, there are sometimes other controls that are possible. For example,most operating systems provide some kind of method to suspend a process (stop it from running for a while) and then resume it (continue it running). Status: There are usually interfaces to get some status information about a process as well, such as how long it has run for, or what state it is in. 进程创建: A Little More Detail 从磁盘将程序加载到内存地址空间早期操作系统: 一次全部加载指令和数据 -&gt; 现代操作系统: 懒加载，每次只加载进程运行时需要的部分指令和数据(paging和swapping技术) 分配stack空间(C语言中用于局部变量、函数参数、返回地址),操作系统还需要将main；函数参数填充到stack中(eg. argc&amp;argv) 分配heap(C语言中用于动态分配内存，malloc分配，free释放，heap大小根据请求动态增长) I/O相关操作(eg. 在unix系统中，每个进程默认关联三个打开的文件描述符:标准输入、标准输出和标准出错，更多I/O相关内存位于持久化部分) 进程状态 Running: In the running state, a process is running on a processor.This means it is executing instructions. Ready: In the ready state, a process is ready to run but for some reason the OS has chosen not to run it at this given moment. Blocked: In the blocked state, a process has performed some kind of operation that makes it not ready to run until some other event takes place. A common example: when a process initiates an I/O request to a disk, it becomes blocked and thus some other process can use the processor. 操作系统数据结构 Information an OS needs to track about each process in the xv6 kernel:123456789101112131415161718192021222324252627282930313233// the registers xv6 will save and restore// to stop and subsequently restart a processstruct context &#123;int eip;int esp;int ebx;int ecx;int edx;int esi;int edi;int ebp;&#125;;// the different states a process can be inenum proc_state &#123; UNUSED, EMBRYO, SLEEPING,RUNNABLE, RUNNING, ZOMBIE &#125;;// the information xv6 tracks about each process// including its register context and statestruct proc &#123;char *mem; // Start of process memoryuint sz; // Size of process memorychar *kstack; // Bottom of kernel stack// for this processenum proc_state state; // Process stateint pid; // Process IDstruct proc *parent; // Parent processvoid *chan; // If !zero, sleeping on chanint killed; // If !zero, has been killedstruct file *ofile[NOFILE]; // Open filesstruct inode *cwd; // Current directorystruct context context; // Switch here to run processstruct trapframe *tf; // Trap frame for the// current interrupt&#125;; 一些术语： The process is the major OS abstraction of a running program. At any point in time, the process can be described by its state: the contents of memory in its address space, the contents of CPU registers (including the program counter and stack pointer, among others),and information about I/O (such as open files which can be read or written). The process API consists of calls programs can make related to processes. Typically, this includes creation, destruction,and other useful calls. Processes exist in one of many different process states, including running, ready to run, and blocked. Different events (e.g., getting scheduled or descheduled, or waiting for an I/O to complete) transition a process from one of these states to the other. A process list contains information about all processes in the system. Each entry is found in what is sometimes called a process control block (PCB), which is really just a structure that contains information about a specific process. 进程API (实用内容)//todo 底层机制: Limited Direct Execution虚拟化CPU-&gt;同时运行多个进程(的假象)idea: 分时复用CPUchallenges: performance : 高性能 control : OS保留控制能力 实现: 硬件支持+软件实现 基本技术: 限制直接执行(Limited Direct Execution) the problem without “Limited”: 限制操作 进程切换 problem 1 : Restricted Operations通过系统调用限制特权指令的执行：即中断机制 problem 2 : Switching Between Processes A Cooperative Approach: Wait For System Calls通过系统调用陷入内核 A Non-Cooperative Approach: The OS Takes Control时钟中断:使内核获得CPU控制 由时钟中断构造的进程切换有两次寄存器的保存和恢复，第一次发生在时钟中断发生时，由硬件将user registers保存到进程内核栈中，第二次发生在操作系统进行进程切换时，软件将kernel registers保存到进程控制块中。 处理中断/陷入时发生中断/陷入并行部分将做详细讨论: 主要是 关中断和锁机制 上下文切换(context switch) -&gt; 进程切换]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>OSTEP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu16.04配置tpcc-mysql]]></title>
    <url>%2F2019%2F04%2F08%2Fubuntu16-04%E9%85%8D%E7%BD%AEtpcc-mysql%2F</url>
    <content type="text"><![CDATA[项目地址\ 安装mysql 12$ sudo apt install mysql-server$ sudo apt install libmysqlclient-dev #解决mysql_config缺失问题 编译 12$ cd src$ make 配置tpcc-mysql 创建数据库tpcctest 1$ sudo mysqladmin create tpcctest -p 创建表 1$ mysql tpcctest &lt; create_table.sql -u root -p 创建indexes和FK 1$ mysql tpcctest &lt; add_fkey_idx.sql -u root -p 填充数据 1$ ./tpcc_load -h 127.0.0.1 -d tpcctest -u root -p "123" -w 100 运行 1$ ./tpcc_start -h 127.0.0.1 -p 3306 -d tpcctest -u root -p "123" -c 32 -r 10 -l 10800 参考： 项目主页 TPCC-Mysql 测试]]></content>
      <categories>
        <category>benchmark</category>
      </categories>
      <tags>
        <tag>tpcc-mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu16.04配置SPARK-bench]]></title>
    <url>%2F2019%2F04%2F07%2Fubuntu16-04%E9%85%8D%E7%BD%AESPARK-bench%2F</url>
    <content type="text"><![CDATA[先看官网:直达链接运行SPARK-bench需要配置java环境和spark环境。具体可以google。这里简单介绍一下。 java环境配置 下载jdk包：jdk8 解压文件123$ tar -xvf jdk-8u201-linux-x64.tar.gz$ sudo mkdir /usr/lib/jdk$ mv jdk1.8.0_201 /usr/lib/jdk/ 配置环境变量在/etc/profile添加以下内容 12345#set java environmentexport JAVA_HOME=/usr/lib/jdk/jdk1.8.0_201export JRE_HOME=$&#123;JAVA_HOME&#125;/jreexport CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/libexport PATH=$&#123;JAVA_HOME&#125;/bin:$PATH 如果只是对当前用户更改环境变量，可以在~/.bashrc中修改。 spark环境配置 下载spark：spark 解压文件123$ tar -xvf spark-2.4.1-bin-hadoop2.7.tgz$ sudo mkdir /usr/lib/spark$ sudo mv spark-2.4.1-bin-hadoop2.7 /usr/lib/spark/ 配置环境变量在/etc/profile添加以下内容 123#set spark environmentexport SPARK_HOME=/usr/lib/spark/spark-2.4.1-bin-hadoop2.7export PATH=$&#123;SPARK_HOME&#125;/bin:$PATH 如果只是对当前用户更改环境变量，可以在~/.bashrc中修改。 配置Spark-Bench 下载spark-bench：releases page on Github 解压1$ tar -xvf spark-bench_2.3.0_0.4.0-RELEASE_99.tgz 配置环境变量： 第一种方式：设置bash环境变量 修改bin/spark-bench-env.sh文件中的SPARK_HOME 和 SPARK_MASTER_HOST变量。 第二种方式：修改配置文件(推荐)参考官方文档 运行]]></content>
      <categories>
        <category>benchmark</category>
      </categories>
      <tags>
        <tag>SPARK-bench</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[office2016零售版转VOL版]]></title>
    <url>%2F2019%2F03%2F27%2Foffice2016%E9%9B%B6%E5%94%AE%E7%89%88%E8%BD%ACVOL%E7%89%88%2F</url>
    <content type="text"><![CDATA[下载脚本管理员下运行脚本，选择要转换的选项，填入秘钥：XQNVK-8JYDB-WJ9W3-YJ8YR-WFG99 各版本vol秘钥]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>office</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu18.04配置PARSEC benchmark]]></title>
    <url>%2F2019%2F03%2F21%2Fubuntu18-04%E9%85%8D%E7%BD%AEPARSEC-benchmark%2F</url>
    <content type="text"><![CDATA[官方文档 安装必要环境 1sudo apt install make gcc g++ 下载PARSEC 3.0 1wget http://parsec.cs.princeton.edu/download/3.0/parsec-3.0.tar.gz 解压文件 12tar -xzf parsec-3.0.tar.gzcd parsec-3.0 运行脚本配置环境变量 1source env.sh 编译/运行/卸载 benchmarks 12345678910parsecmgmt -a build -p streamcluster #编译streamclusterparsecmgmt -a run -p streamcluster #运行streamcluster，默认使用test数据集parsecmgmt -a fulluninstall -p streamcluster #卸载streamcluster#Note that it may take several hours depending on your machineparsecmgmt -a build -p all #编译所有的benchparsecmgmt -a run -p all #运行所有的benchparsecmgmt -a fulluninstall -p streamcluster #卸载所有的benchparsecmgmt -a info -p streamcluster #查看streamcluster的信息，包括各种input数据集parsecmgmt -a run -p streamcluster -i native #使用native数据集测试 数据集可以参考官方介绍:注意，有的bench可能不止上述的输入，具体使用info选项查看。 环境配置：first，建议只装自己需要的且一个一个benchmark 装，除非很有耐心。1.blackscholes : 首先安装sudo apt-get install m42.dedup : encoder.c 增加 #include &lt;sys/stat.h&gt; 注：我在测试得时候发现 这个方法失效，暂时没有编译出来3.vips：缺少zlib sudo apt-get install zlib1g-dev 然后gettext 错误 sudo apt-get install libgtk2.0-dev http://www.cnblogs.com/soli/archive/2008/01/14/1039010.html4.raytrace:mesa 安装xorg-dev5.facesim:3.0中缺少input，可在有用网址2中找到 第一遍装的时候感觉很费劲，这次好多了，但也没有发现多少缺少的。只装了blackscholes，bodytrace，canneal，dedup，facesim，raytrace，streamcluster，swaptions，vips,x264.有用的网址：http://parsec.cs.princeton.edu/parsec3-doc.htmhttp://www.multi2sim.org/svn/m2s-bench-parsec-2.1/facesim/data-small/Face_Data/Eftychis_840k/ 参考：ubuntu 12.04 编译 parsec3.0 parsec-tutorial]]></content>
      <categories>
        <category>benchmark</category>
      </categories>
      <tags>
        <tag>PARSEC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DaCapo benchmark环境搭建]]></title>
    <url>%2F2019%2F03%2F19%2FDaCapo-benchmark%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[虚拟化性能测试需要使用benchmark测试，这里使用了DaCapo来实现。DaCapo基于java编写，需要java运行时环境，所以需要配置java环境。项目主页 在配置环境之前需要将host的hugepage关闭，运行一下命令关闭： 1sudo bash -c "echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled" 在guest中配置java 123sudo add-apt-repository ppa:webupd8team/javasudo apt updatesudo apt install oracle-java8-installer 使用java --version测试是否安装成功 下载DaCapo包下载地址：dacapo-9.12-MR1-bach.jar 常用命令 12345678java -jar dacapo-9.12-MR1-bach.jar #获取指令使用信息java -jar dacapo-9.12-MR1-bach.jar -l #列出所有benchmarkjava -jar dacapo-9.12-MR1-bach.jar avrora（benchmark名) #运行相应benchmark#dacapo对每一个benchmark提供了三种不同大小的负载java -jar dacapo-9.12-MR1-bach.jar -s small avrora #以小负载运行benchmarkjava -jar dacapo-9.12-MR1-bach.jar -s default avrora #以默认负载运行benchmarkjava -jar dacapo-9.12-MR1-bach.jar -s large avrora #以大负载运行benchmark 在不同负载下，同一个benchmark运行时间不同。benchmark相关的配置文件在文件夹dacapo-9.12-MR1-bach.jar/cnf中。附件：《The DaCapo Benchmarks: Java Benchmarking Development and Analysis》]]></content>
      <categories>
        <category>虚拟化</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[转]Linux内核高端内存]]></title>
    <url>%2F2019%2F03%2F18%2F%E8%BD%AC-Linux%E5%86%85%E6%A0%B8%E9%AB%98%E7%AB%AF%E5%86%85%E5%AD%98%2F</url>
    <content type="text"><![CDATA[原文地址 Linux内核地址映射模型x86 CPU采用了段页式地址映射模型。进程代码中的地址为逻辑地址，经过段页式地址映射后，才真正访问物理内存。段页式机制如下图。 Linux内核地址空间划分通常32位Linux内核地址空间划分0~3G为用户空间，3~4G为内核空间。注意这里是32位内核地址空间划分，64位内核地址空间划分是不同的。 Linux内核高端内存的由来当内核模块代码或线程访问内存时，代码中的内存地址都为逻辑地址，而对应到真正的物理内存地址，需要地址一对一的映射，如逻辑地址0xc0000003对应的物理地址为0x3，0xc0000004对应的物理地址为0x4，… …，逻辑地址与物理地址对应的关系为 物理地址 = 逻辑地址 – 0xC0000000 假设按照上述简单的地址映射关系，那么内核逻辑地址空间访问为0xc0000000 ~ 0xffffffff，那么对应的物理内存范围就为0x0 ~ 0x40000000，即只能访问1G物理内存。若机器中安装8G物理内存，那么内核就只能访问前1G物理内存，后面7G物理内存将会无法访问，因为内核的地址空间已经全部映射到物理内存地址范围0x0 ~ 0x40000000。即使安装了8G物理内存，那么物理地址为0x40000001的内存，内核该怎么去访问呢？代码中必须要有内存逻辑地址的，0xc0000000 ~ 0xffffffff的地址空间已经被用完了，所以无法访问物理地址0x40000000以后的内存。 显然不能将内核地址空间0xc0000000 ~ 0xfffffff全部用来简单的地址映射。因此x86架构中将物理地址划分三部分：ZONE_DMA、ZONE_NORMAL和ZONE_HIGHMEM。ZONE_HIGHMEM即为高端内存，这就是内存高端内存概念的由来。 在x86结构中，三种类型的区域如下： ZONE_DMA 内存开始的16MBZONE_NORMAL 16MB~896MBZONE_HIGHMEM 896MB ~ 结束 Linux内核高端内存的理解前面我们解释了高端内存的由来。 Linux将内核地址空间划分为三部分ZONE_DMA、ZONE_NORMAL和ZONE_HIGHMEM，高端内存HIGH_MEM地址空间范围为0xF8000000 ~ 0xFFFFFFFF（896MB～1024MB）。那么如内核是如何借助128MB高端内存地址空间是如何实现访问可以所有物理内存？ 当内核想访问高于896MB物理地址内存时，从0xF8000000 ~ 0xFFFFFFFF地址空间范围内找一段相应大小空闲的逻辑地址空间，借用一会。借用这段逻辑地址空间，建立映射到想访问的那段物理内存（即填充内核PTE页面表），临时用一会，用完后归还。这样别人也可以借用这段地址空间访问其他物理内存，实现了使用有限的地址空间，访问所有所有物理内存。如下图。例如内核想访问2G开始的一段大小为1MB的物理内存，即物理地址范围为0x80000000 ~ 0x800FFFFF。访问之前先找到一段1MB大小的空闲地址空间，假设找到的空闲地址空间为0xF8700000 ~ 0xF87FFFFF，用这1MB的逻辑地址空间映射到物理地址空间0x80000000 ~ 0x800FFFFF的内存。映射关系如下：当内核访问完0x80000000 ~ 0x800FFFFF物理内存后，就将0xF8700000 ~ 0xF87FFFFF内核线性空间释放。这样其他进程或代码也可以使用0xF8700000 ~ 0xF87FFFFF这段地址访问其他物理内存。从上面的描述，我们可以知道高端内存的最基本思想：借一段地址空间，建立临时地址映射，用完后释放，达到这段地址空间可以循环使用，访问所有物理内存。看到这里，不禁有人会问：万一有内核进程或模块一直占用某段逻辑地址空间不释放，怎么办？若真的出现的这种情况，则内核的高端内存地址空间越来越紧张，若都被占用不释放，则没有建立映射到物理内存都无法访问了。在香港尖沙咀有些写字楼，洗手间很少且有门锁的。客户要去洗手间的话，可以向前台拿钥匙，方便完后，把钥匙归还到前台。这样虽然只有一个洗手间，但可以满足所有客户去洗手间的需求。要是某个客户一直占用洗手间、钥匙不归还，那么其他客户都无法上洗手间了。Linux内核高端内存管理的思想类似。 Linux内核高端内存的划分内核将高端内存划分为3部分：VMALLOC_START~VMALLOC_END、KMAP_BASE~FIXADDR_START和FIXADDR_START~4G。对于高端内存，可以通过 alloc_page() 或者其它函数获得对应的 page，但是要想访问实际物理内存，还得把 page 转为线性地址才行（为什么？想想 MMU 是如何访问物理内存的），也就是说，我们需要为高端内存对应的 page 找一个线性空间，这个过程称为高端内存映射。对应高端内存的3部分，高端内存映射有三种方式： 映射到”内核动态映射空间”（noncontiguous memory allocation）这种方式很简单，因为通过 vmalloc() ，在”内核动态映射空间”申请内存的时候，就可能从高端内存获得页面（参看 vmalloc 的实现），因此说高端内存有可能映射到”内核动态映射空间”中。 持久内核映射（permanent kernel mapping）如果是通过 alloc_page() 获得了高端内存对应的 page，如何给它找个线性空间？内核专门为此留出一块线性空间，从 PKMAP_BASE 到 FIXADDR_START ，用于映射高端内存。在 2.6内核上，这个地址范围是 4G-8M 到 4G-4M 之间。这个空间起叫”内核永久映射空间”或者”永久内核映射空间”。这个空间和其它空间使用同样的页目录表，对于内核来说，就是 swapper_pg_dir，对普通进程来说，通过 CR3 寄存器指向。通常情况下，这个空间是 4M 大小，因此仅仅需要一个页表即可，内核通过来 pkmap_page_table 寻找这个页表。通过 kmap()，可以把一个 page 映射到这个空间来。由于这个空间是 4M 大小，最多能同时映射 1024 个 page。因此，对于不使用的的 page，及应该时从这个空间释放掉（也就是解除映射关系），通过 kunmap() ，可以把一个 page 对应的线性地址从这个空间释放出来。 临时映射（temporary kernel mapping）内核在 FIXADDR_START 到 FIXADDR_TOP 之间保留了一些线性空间用于特殊需求。这个空间称为”固定映射空间”在这个空间中，有一部分用于高端内存的临时映射。 这块空间具有如下特点：（1）每个 CPU 占用一块空间（2）在每个 CPU 占用的那块空间中，又分为多个小空间，每个小空间大小是 1 个page，每个小空间用于一个目的，这些目的定义在 kmap_types.h 中的 km_type 中。 当要进行一次临时映射的时候，需要指定映射的目的，根据映射目的，可以找到对应的小空间，然后把这个空间的地址作为映射地址。这意味着一次临时映射会导致以前的映射被覆盖。通过 kmap_atomic() 可实现临时映射。 常见问题： 用户空间（进程）是否有高端内存概念？用户进程没有高端内存概念。只有在内核空间才存在高端内存。用户进程最多只可以访问3G物理内存，而内核进程可以访问所有物理内存。 64位内核中有高端内存吗？目前现实中，64位Linux内核不存在高端内存，因为64位内核可以支持超过512GB内存。若机器安装的物理内存超过内核地址空间范围，就会存在高端内存。 用户进程能访问多少物理内存？内核代码能访问多少物理内存？32位系统用户进程最大可以访问3GB，内核代码可以访问所有物理内存。64位系统用户进程最大可以访问超过512GB，内核代码可以访问所有物理内存。 高端内存和物理地址、逻辑地址、线性地址的关系？高端内存只和物理地址有关系，和线性地址、逻辑地址没有直接关系。 为什么不把所有的地址空间都分配给内核？若把所有地址空间都给内存，那么用户进程怎么使用内存？怎么保证内核使用内存和用户进程不起冲突？]]></content>
      <categories>
        <category>linux内核</category>
      </categories>
      <tags>
        <tag>linux内核</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git设置和取消代理]]></title>
    <url>%2F2019%2F03%2F08%2Fgit%E8%AE%BE%E7%BD%AE%E5%92%8C%E5%8F%96%E6%B6%88%E4%BB%A3%E7%90%86%2F</url>
    <content type="text"><![CDATA[查看当前代理设置：12git config --global http.proxygit config --global https.proxy 设置代理：1234git config --global http.proxy 'http://127.0.0.1:1080'git config --global https.proxy 'https://127.0.0.1:1080'git config --global http.proxy 'socks5://127.0.0.1:1080' git config --global https.proxy 'socks5://127.0.0.1:1080' 取消设置：12git config --global --unset http.proxygit config --global --unset https.proxy]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git使用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[台湾清华彭明辉教授的研究生手册(学习方法论)]]></title>
    <url>%2F2019%2F03%2F08%2F%E5%8F%B0%E6%B9%BE%E6%B8%85%E5%8D%8E%E5%BD%AD%E6%98%8E%E8%BE%89%E6%95%99%E6%8E%88%E7%9A%84%E7%A0%94%E7%A9%B6%E7%94%9F%E6%89%8B%E5%86%8C-%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E8%AE%BA%2F</url>
    <content type="text"><![CDATA[原文地址]]></content>
      <categories>
        <category>方法论</category>
      </categories>
      <tags>
        <tag>方法论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu下KVM虚拟机创建]]></title>
    <url>%2F2019%2F02%2F28%2Fubuntu%E4%B8%8BKVM%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%88%9B%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[网上关于KVM虚拟机创建的文章有很多，但是都是只提供命令，没有解释。对于初学者很不友好，这里记录下我自己的实践。因为我的服务器使用的是ubuntu16.04，所以以下操作都是基于此系统。我是在windows下使用MobaXterm来连接我自己的服务器的，这里强力推荐这款软件，非常方便。 以下代码’#’后的内容为注释‘$’后为执行命令 验证主机是否支持硬件虚拟化12cat /proc/cpuinfo | grep svm # AMD硬件cat /proc/cpuinfo | grep vmx # Intel硬件 svm是ADM的ADM-V虚拟化技术标识，全称secure virtual machine，vmx是Intel的硬件虚拟化技术VT-x，标识是vmx，全称为virtual machine extension。通过查询cpuinfo文件，可以知道硬件是否支持虚拟化。若返回结果中有svm或者vmx则说明硬件支持虚拟化。 安装必要依赖1$ sudo apt install qemu-kvm libvirt-bin virtinst bridge-utils virt-viewer virt-manager kvm:linux系统自带，已经编译进linux内核 qemu-kvm：KVM的设备模拟器，因为KVM只负责CPU和内存的虚拟化，独立无法完成整个系统的虚拟化，所以KVM开发者使用成熟的qemu来完成其他部件的虚拟化，qemu负责虚拟机的管理，kvm负责加速 libvirt：Libvirt是用于管理虚拟化平台的开源的API，后台程序和管理工具。它可以用于管理KVM、Xen、VMware ESX，QEMU和其他虚拟化技术 virtinst: 虚拟机创建（virt-install）和克隆工具（vrit-clone）等 birdge-utils: 用于桥接网卡的工具 virt-viewer：连接虚拟机屏幕的工具，需要桌面环境支持，使用mobaXterm可以远程使用x11图形界面，非常方便。 virt-manager：gui虚拟机管理工具，类似于windows上的vmware workstation KVM管理工具的一些注解及一些实用工具 libvirt：操作和管理KVM虚机的虚拟化API，使用C语言编写，可以由Python,Ruby, Perl, PHP, Java等语言调用。可以操作包括KVM，vmware，XEN，Hyper-v, LXC，virtualbox等 Hypervisor。 virsh：基于libvirt的命令行工具，后面需要大量使用 virt-v2v：虚机格式迁移工具，该工具与virt-sysprep都包含在包libguestfs-tools中，后面布署中会用到 virt-install：创建KVM虚机的命令行工具 virt-viewer：连接到虚拟机屏幕的工具，需要主机有桌面环境，该工具需要单独安装sudo apt-get install virt-viewer virt-clone：虚机克隆工具 virt-top：类似于linux系统下的top命令，可以显示所有虚拟机CPU、内存等使用情况，该工具需要单独安装sudo apt-get install virt-top 虚拟机创建默认情况下，在安装完上述环境后，会自动配置好一个默认的网络环境default,可以使用如下命令查看：1$ sudo virsh net-list --all 假如不小心通过brctl（用于管理桥接网络的工具）删除了default网络，可以通过重新加载预置的XML文件来恢复：123456$ sudo virsh net-define /usr/share/libvirt/networks/default.xml #重新定义网络Network default defined from /usr/share/libvirt/networks/default.xml$ sudo virsh net-autostart default #设置default开机自动启动Network default marked as autostarted$ sudo virsh net-start default #启动网络defaultNetwork default started 这里默认的配置是nat模式，即guestOS可以通过host上网，而在外部看不到guest。 为了让非root用户可以直接使用virsh命令管理虚拟机，需要将普通用户加入到kvm和libvirt用户组中：12$ sudo adduser &lt;youruser&gt; kvm$ sudo adduser &lt;youruser&gt; libvirtd centos 使用：12$ sudo gpasswd -a &lt;youruser&gt; kvm$ sudo gpasswd -a &lt;youruser&gt; libvirt 这个时候重新登录就会使新的用户组成员生效了。 使用virt-manager创建虚拟机新手推荐使用图形化界面创建虚拟机。使用MobaXterm连接服务器时原生支持x11，所以直接在shell中运行virt-manager就可以了，配置同vmware类似，这里就不多介绍了注意:在centos 7 上使用virt-manager安装时，显示协议选择spice时，需要gtk支持：1$ sudo yum install gtk3 centos 7上安装的virsh的uri默认为qemu:///session,可以在用户目录下使用配置文件更改：12$ cd /home/&#123;user&#125;/.config/libvirt$ echo uri_default = "qemu:///system" &gt;&gt; libvirt.conf 使用virsh-install创建虚拟机使用virsh-install命令可以在命令行下配置虚拟机：1234567891011$ virt-install \ --virt-type=kvm \ --name=ubuntuserver1604 \ --ram=2048 \ --vcpus=2 \ --os-variant=ubuntu16.04 \ --hvm \ --cdrom=/home/colin/vhost/iso/ubuntuServer1604.iso \ --network=default,model=virtio \ --graphics vnc,listen=0.0.0.0 \ --disk path=/home/colin/vhost/image/ubuntuserver1604-2g-original.qcow2,size=20,bus=virtio,format=qcow2 各个参数解释：下面是各参数的意义： –virt-type=kvm: 使用KVM作为虚拟机监视器 –name=ubuntuserver1604: 虚拟机实例的名字，每个虚拟机的名字都不能一样，不能有空格 –ram=2048: 指定虚拟机内存大小，单位是Mb –vcpus=2: 为虚拟机指定分配的虚拟CPU核数 –os-variant=ubuntu16.04: 指定虚拟机系统所属系列以优化虚拟机参数，可以通过命令osinfo-query os 来显示所有支持的系统列表，osinfo-query在包libosinfo-bin中 sudo apt-get install libosinfo-bin –hvm: 启用全虚拟化，KVM虚拟机支持全虚拟化，属于优化性参数 –cdrom=/home/vhost/iso/ubuntuServer1604.iso: 指定作为虚拟机光驱内容的设备或文件，可以是主机的CDROM或者iso文件。 –network network=default,model=virtio: 将虚拟机连接到主机网络，此处连接到一个名为defalut的虚拟网络（即让虚拟机使用NAT模式上网），网卡模式设置为virtio。如果使用桥接模式，则只需要改参数为–network=bridge=br0,model=virtio即可。 –graphics vnc: 设置虚拟机的console并将其输出到VNC，这样就可以通过VNC来连接虚拟机了。同时可以指定vnc的端口和监听范围以及密码: –vncport=5910 –vnclisten=0.0.0.0。默认情况下端口为从5900开始的第一个空闲端口，监听范围为本机127.0.0.1，修改为0.0.0.0以使外网主机可以连接。后面会讲对于只支持SSH协议的情况下，如何通过SSH隧道连接，所以是否设置为0.0.0.0没有影响，但能设置为0.0.0.0的话，还是设置为0.0.0.0，毕竟直接通过VNC连接更加方便。这些参数也可以在/etc/libvirt/qemu.conf中修改，以使其对所有虚拟机生效，VNC默认连接没有密码。VNC可以理解为linux下的远程桌面 –disk path=/home/vhost/image/ubuntuserver1604-2g-original.qcow2,size=20,bus=virtio,format=qcow2: 指定虚拟机所使用的存储路径，大小为20G，disk bus类型为virtio，磁盘格式为raw，如果不指定fortmat，则默认格式即为raw。 网络和磁盘建议都设置为virtio，virtio即启动优化的虚拟机专用IO驱动，性能更好。磁盘格式使用qcow2更好，因为qcow2格式即QEMU支持的QEMU Copy On Write磁盘格式，是优化后的磁盘格式，支持快照，并且是使用多少占用多少空间。例如你分配了20G大小，如果是raw格式，则立即占用20G，而qcow2则是从很小开始，用多少，占用多少。之前有些人说qcow2性能不如raw，这两种格式可以使用qemu-img进行转换，qemu-img在包qemu-utils中。 KVM管理常用命令KVM虚拟机默认配置文件位置: /etc/libvirt/qemu/，该目录下存放了所有创建过的虚拟机配置文件。1234567891011121314151617$ virsh list # 查看正在运行的虚拟主机列表$ osinfo-query os # 查看virt-install所支持的OS参数列表$ virsh list --all # 查看所有的虚拟机列表$ virsh dominfo ubuntuserver1604 # 查看虚拟机信息$ virsh start ubuntuserver1604 # 启动虚拟机$ virsh shutdown ubuntuserver1604 # 关闭虚拟机$ virsh suspend ubuntuserver1604 # 挂起虚拟机$ virsh reboot ubuntuserver1604 #软重启（安全重启，相当于在虚拟机内部点击重启选项）虚拟机$ virsh reset ubuntuserver1604 # 硬重启虚拟机（不安全，有可能数据丢失，相当于强制按主机上的重启按钮）$ virsh autostart ubuntuserver1604 # 设置虚拟机随着宿主主机开机自动启动(开机自动启动的虚拟机配置文件会自动在目录/etc/libvirt/qemu/autostart/目录下生成)$ virsh autostart --disable ubuntuserver1604 # 取消开机自启动$ virsh destroy ubuntuserver1604 # 强制关闭虚拟机电源$ virsh edit ubuntuserver1604 # 编辑虚拟机配置文件$ virsh uri # 查看当前主机上hypervisor的链接路径$ virsh undefine ubuntuserver1604 # 移除虚拟机定义，即从虚拟机列表中移除虚拟机 该命令只是删除/etc/libvirt/qemu/目录下名为ubuntuserver1604.xml的配置文件，并不会删除虚拟机磁盘文件$ virsh define ubuntuserver1604.xml #通过虚拟机配置文件重新定义虚拟机 注意，使用virsh shutdown ubuntuserver1604命令时，由于virsh实际上不能对虚拟机进行关机，只有虚拟机配置了acpid服务之后才能通过virsh进行关机，配置命令为：12$ sudo chkconfig acpid on$ sudo service acpid restart # 注意这是指在虚拟机中配置该服务]]></content>
      <categories>
        <category>虚拟化</category>
      </categories>
      <tags>
        <tag>KVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu安装nodejs]]></title>
    <url>%2F2018%2F04%2F07%2Fubuntu%E5%AE%89%E8%A3%85nodejs%2F</url>
    <content type="text"><![CDATA[​ 通过ubuntu包管理器安装nodejs，需要引入第三方库。nodejs官方提供了添加脚本。在deb.nodesource.com 中可以看到。在终端中运行:12curl -sL https://deb.nodesource.com/setup_8.x | sudo -E bash -sudo apt-get install -y nodejs 就可以安装最新的nodejs 8.x版本了。其他版本可在deb.nodesource.com上查找。]]></content>
      <categories>
        <category>ubuntu</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>nodejs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用IntelliJ IDEA创建Hibernate项目]]></title>
    <url>%2F2017%2F07%2F09%2F%E4%BD%BF%E7%94%A8IntelliJ-IDEA%E5%88%9B%E5%BB%BAHibernate%E9%A1%B9%E7%9B%AE%2F</url>
    <content type="text"><![CDATA[最近正在学习web开发的三大框架即SSH ，目前正在学习Hibernate 操作数据库，由于其版本的更新，其中需要注意到的一些小问题。 下面是在IntelliJ IDEA下创建一个Hibernate项目的过程。目前来说，IntelliJ IDEA作为一款优秀的IDE开发工具，其工具集成度很高。所以我们可以直接建立一个Hibernate项目：勾选Hibernate框架，这里我们看到Hibernate的最新版是5.2.10，勾选Create default hibernate configuratuion and main class ，让IDE为我们自动生成Hibernate的配置文（Hibernate.cfg.xml)， 等待IDE为我们下载好所需的jar包，完成项目的创建。 接下来我们创建一个包，包名为com.colins110.test，看到我们的Hibernate 配置文件已经自动创建了，我们要对配置文件进行一些修改：这里我使用的是mysql，需要导入mysql的驱动包，这里我是用的是mysql-connector-java-5.1.42，在mysql官网可以获取。配置如下: 连接url：jdbc:mysql:///hibernate?useUnicode=true&amp;characterEncoding=UTF-8 我的数据库名为hibernate ，?后表明使用unicode字符集，在xml文件中&amp;需要写成&amp;amp;。 数据库驱动：com.mysql.jdbc.Driver这里使用的是上面导入的驱动包 用户名：默认为root 密码：我的密码为空 使用方言：mysql方言有多种，这里选择org.hibernate.dialect.MySQL5Dialect新版方言 show_sql属性：在命令行显示生成的sql语句format_sql属性：格式化输出sql语句 hbm2ddl属性：设置为create，每次重新创建表 这样我们的Hibernate环境就配置好了 接下来需要配置一个实体类，用来表示数据库中的一个表，每个实体类对象则表示表中的一条记录，这样的话，我们在编程的时候只需要面向对象编程，而不需要写SQL语句了。 在这里我建立了一个Students类，这是一个典型的java Bean12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576package com.colins110.test;import java.util.Date;/** * Created by colin on 2017/7/9 0009. *///学生类public class Students &#123; private int sid; private String sname; private String gender; private Date birthday; private String address; public Students() &#123;&#125; public Students(int sid, String sname, String gender, Date birthday, String address) &#123; this.sid = sid; this.sname = sname; this.gender = gender; this.birthday = birthday; this.address = address; &#125; public int getSid() &#123; return sid; &#125; public void setSid(int sid) &#123; this.sid = sid; &#125; public String getSname() &#123; return sname; &#125; public void setSname(String sname) &#123; this.sname = sname; &#125; public String getGender() &#123; return gender; &#125; public void setGender(String gender) &#123; this.gender = gender; &#125; public Date getBirthday() &#123; return birthday; &#125; public void setBirthday(Date birthday) &#123; this.birthday = birthday; &#125; public String getAddress() &#123; return address; &#125; public void setAddress(String address) &#123; this.address = address; &#125; @Override public String toString() &#123; return "Students&#123;" + "sid=" + sid + ", sname='" + sname + '\'' + ", gender='" + gender + '\'' + ", birthday=" + birthday + ", address='" + address + '\'' + '&#125;'; &#125;&#125; 现在需要建立一个对应的配置文件，指明java Bean和数据库中表的映射关系，这里是Students.hbm.xml。12345678910111213141516171819202122232425&lt;?xml version='1.0' encoding='utf-8'?&gt;&lt;!DOCTYPE hibernate-mapping PUBLIC "-//Hibernate/Hibernate Mapping DTD 3.0//EN" "http://www.hibernate.org/dtd/hibernate-mapping-3.0.dtd"&gt;&lt;hibernate-mapping&gt; &lt;class name="com.colins110.test.Students" table="Students"&gt; &lt;id name="sid" type="int"&gt; &lt;column name="id" /&gt; &lt;generator class="assigned"/&gt; &lt;/id&gt; &lt;property name="sname" type="java.lang.String"&gt; &lt;column name="name" /&gt; &lt;/property&gt; &lt;property name="gender" type="java.lang.String"&gt; &lt;column name="sex" /&gt; &lt;/property&gt; &lt;property name="birthday" type="java.util.Date"&gt; &lt;column name="birthday" /&gt; &lt;/property&gt; &lt;property name="address" type="java.lang.String"&gt; &lt;column name="address"/&gt; &lt;/property&gt; &lt;/class&gt;&lt;/hibernate-mapping&gt; 下载需要将Students.hbm.xml映射文件配置到配置文件中：下面使用Juint4对hibernate进行测试 编写测试代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package com.colins110.test;import org.hibernate.Session;import org.hibernate.SessionFactory;import org.hibernate.Transaction;import org.hibernate.boot.registry.StandardServiceRegistryBuilder;import org.hibernate.cfg.Configuration;import org.hibernate.service.ServiceRegistry;import org.junit.After;import org.junit.Before;import org.junit.Test;import java.util.Date;import static org.junit.Assert.*;/** * Created by colin on 2017/7/9 0009. */public class StudentsTest &#123; private Configuration config; private SessionFactory sf; private Session session; private Transaction transaction; @Before public void setUp() throws Exception &#123; config=new Configuration().configure(); ServiceRegistry serviceRegistry=new StandardServiceRegistryBuilder().applySettings(config.getProperties()).configure().build(); sf=config.buildSessionFactory(serviceRegistry); session=sf.openSession(); transaction=session.beginTransaction(); &#125; @After public void tearDown() throws Exception &#123; transaction.commit(); session.close(); sf.close(); &#125; @Test public void test() &#123; Students user=new Students(120,"董健","男",new Date(),"四川"); session.save(user); &#125;&#125; 注意： 在5.x版的Hibernate中，需要使用ServiceRegistry serviceRegistry=new StandardServiceRegistryBuilder().applySettings(config.getProperties()).configure().build();来注册服务在4.x中使用ServiceRegistry serviceRegistry=new ServiceRegistryBuilder().applySettings(config.getProperties()).buildServiceRegistry();来注册服务]]></content>
      <categories>
        <category>Java Web</category>
      </categories>
      <tags>
        <tag>IntelliJ IDEA</tag>
        <tag>Hibernate</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用win10创意者更新自带工具MBR2GPT完成系统盘的MBR到GPT的无损转换]]></title>
    <url>%2F2017%2F06%2F11%2F%E4%BD%BF%E7%94%A8win10%E5%88%9B%E6%84%8F%E8%80%85%E6%9B%B4%E6%96%B0%E8%87%AA%E5%B8%A6%E5%B7%A5%E5%85%B7MBR2GPT%E5%AE%8C%E6%88%90%E7%B3%BB%E7%BB%9F%E7%9B%98%E7%9A%84MBR%E5%88%B0GPT%E7%9A%84%E6%97%A0%E6%8D%9F%E8%BD%AC%E6%8D%A2%2F</url>
    <content type="text"><![CDATA[之前如果需要将MBR格式的硬盘转换为GPT硬盘，要么选择格盘重装系统，这样数据会丢失。如果需要数据无损转换的话，手工转换比较复杂，或者可以使用第三方的分区工具完成。这里我们介绍微软官方提供的无损转换工具MBR2GPT，工具已经内置到win10创意者更新里了，这里我们可以在命令行里直接调用！ 这是官方参考文档: 点此阅读 注意事项 在转换过程中会创建UEFI系统分区，这会占用一个MBR主分区，而因为MBR磁盘最多只能有四个主分区，所以待转换的MBR磁盘不能超过四个主分区； BitLocker加密磁盘需要先解除BitLocker加密之后才能使用MBR2GPT进行转换； 即使当前安装的Win10 1703之前的早期Win10版本（1607，1511，1507），依然能够使用MBR2GPT进行转换，只不过需要使用Win10 1703系统盘启动进入WinRE环境，才能运行MBR2GPT工具。 这是我们演示将本机的系统盘转换为GPT文件格式步骤一:启动进入WinRE环境，如果不懂如何进入，请点击阅读 进入后选择命令提示符 步骤二使用命令disk查看里的磁盘序号。 步骤三启动MBR2GPT程序，带上参数/validate和/disk:1，用于指定对1号磁盘（系统盘）进行检查，如果提示successfully说明可以进行转换。1mbr2gpt /validate /disk:1 开始转换完成后类似如下提示:1234567891011121314151617MBR2GPT will now attempt to convert disk 0.If conversion is successful the disk can only be booted in GPT mode.These changes cannot be undone!MBR2GPT: Attempting to convert disk 0MBR2GPT: Retrieving layout of diskMBR2GPT: Validating layout, disk sector size is: 512 bytesMBR2GPT: Trying to shrink the system partitionMBR2GPT: Trying to shrink the OS partitionMBR2GPT: Creating the EFI system partitionMBR2GPT: Installing the new boot filesMBR2GPT: Performing the layout conversionMBR2GPT: Migrating default boot entryMBR2GPT: Adding recovery boot entryMBR2GPT: Fixing drive letter mappingMBR2GPT: Conversion completed successfullyMBR2GPT: Before the new system can boot properly you need to switch the firmware to boot to UEFI mode! 最后记得将主板上的启动模式改为UEFI mode!更多细节参见官方手册]]></content>
      <categories>
        <category>windows</category>
      </categories>
      <tags>
        <tag>windows</tag>
        <tag>分区无损转换</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Markdown语法]]></title>
    <url>%2F2017%2F06%2F06%2FMarkdown%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[这是我的第一篇文章首先，回忆一下Markdown语法 标题 标题可以根据字体大小分为六级，分别用不同数量的#表示【效果】 这是一级标题这是二级标题这是三级标题这是四级标题这是五级标题这是六级标题【输入】123456#这是一级标题##这是二级标题###这是三级标题####这是四级标题#####这是五级标题######这是六级标题 文本 【效果】粗体斜体粗体+斜体【输入】123**这是粗体***这是斜体****这是粗体+斜体*** 图片 【效果】【输入】1![我的博客主页](Markdown语法/我的主页.png) 列表 列表分为有序列表和无序列表无序列表可以通过在每行文本前输入*,+,-来实现【效果】 星号实现的列表 加号实现的列表 减号实现的列表 注意符号与文本之间要有一个空格 【输入】1234* 星号实现的列表+ 加号实现的列表- 减号实现的列表* 注意符号与文本之间要有一个空格 有序列表可以通过在每行文本前面输入数字+.+空格来实现【效果】 第一行 第二行 第三行 【输入】1231. 第一行2. 第二行3. 第三行 引用 【效果】 这是一段引用啦 【输入】1&gt;这是一段引用啦 行内代码块 行内代码块可用于关键字词，将其与普通文本文件分别开来，其用法是在文本内容外套上”`“，即反引号。 【效果】这是一段行内代码块【输入】1`这是一段行内代码块` 代码块 【效果】12345public class test&#123; public static void main()&#123; System.out.println("This is a test_class!"); &#125;&#125; 表格 【效果】|默认|居中|左对齐|右对齐||–|:-:|:-|-:||换行\n换行失败|我的Markdown|不支持|换行||支持斜体|粗体|斜体+粗体|||# 不支持标题|支持链接||支持行内代码块 | 【输入】12345|默认|居中|左对齐|右对齐||--|:-:|:-|-:||换行\n换行失败|我的Markdown|不支持|换行||*支持斜体*|**粗体**|***斜体+粗体***|||# 不支持标题|[支持链接](http://jianshu.com)|![支持图片](https://cdn.sspai.com/attachment/origin/2014/04/15/69488.png?imageMogr2/quality/90/thumbnail/100x)|`支持行内代码块` | 删除线 【效果】删除线【输入】1~~删除线~~ 分割线 分割线可使用*、-来实现。【效果】 【输入】12---***]]></content>
      <categories>
        <category>Markdown</category>
      </categories>
      <tags>
        <tag>Markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Win10进入恢复模式]]></title>
    <url>%2F2017%2F06%2F01%2FWin10%E8%BF%9B%E5%85%A5%E6%81%A2%E5%A4%8D%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[【科普】 什么是windows恢复模式windows恢复环境 (Windows Recovery Environment),，简称WinRE，是微软从Windows Vista开始引入的用于系统恢复和还原的一套环境。WinRE默认安装在系统分区前的隐藏分区中。 那么如何进入呢？ 方法一： Win10单系统开机时按F8键进入WinRE如果你的电脑是Windows10单系统的话，开机不停地按F8键即可进入WInRE。 方法二：通过设置进入WinRE1.打开电脑设置2.进入更新和安全，在恢复选项中点击高级启动立即重启 3.系统重启后进入恢复模式]]></content>
      <categories>
        <category>windows</category>
      </categories>
      <tags>
        <tag>windows</tag>
        <tag>恢复模式</tag>
      </tags>
  </entry>
</search>
